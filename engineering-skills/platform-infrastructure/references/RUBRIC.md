# Rubric (score 1–5 each)

Target: average **≥ 4.0** with no critical 1s in Scope/Contracts or Execution Readiness.

## 1) Scope clarity
1 = vague; boundaries missing  
3 = mostly clear; some scope creep risk  
5 = crisp scope; clear “not in scope”; correct adjacent-skill routing

## 2) Actionability of deliverables
1 = generic advice; no concrete artifacts  
3 = artifacts exist but are thin or underspecified  
5 = artifacts are detailed enough to execute without a meeting

## 3) Platformization rigor
1 = “make a platform” hand-waving  
3 = identifies candidates but weak contracts/migration plan  
5 = clear contracts, ownership, and migration/compat strategy per shared capability

## 4) Quality attributes + measurability
1 = aspirational goals only  
3 = some metrics/SLOs but gaps remain  
5 = measurable targets, measurement method, and ownership (incl. privacy/safety/operability/cost)

## 5) Scaling readiness
1 = reactive; no triggers/lead time  
3 = some limits listed; triggers unclear  
5 = doomsday clock with lead-time-aware triggers, owners, and mitigation projects

## 6) Instrumentation + analytics integrity
1 = client-SDK-centric without data-quality plan  
3 = mixed approach; identity/QA gaps  
5 = server-side canonical events, identity strategy, and automated data-quality checks

## 7) Execution readiness
1 = no roadmap; no owners; no rollout/rollback  
3 = roadmap exists but weak acceptance criteria/dependencies  
5 = sequenced milestones with owners, acceptance criteria, dependencies, and rollout/rollback

