# Examples (Usability Testing)

Use these as “good shape” references for what outputs should look like when this skill is invoked.

## Example 1 — Checkout usability test (typical)

**Prompt:** “Create a usability test plan + moderator guide for our checkout redesign. We’re a B2C web app. Run 6 remote moderated sessions with existing users this week.”

**Expected outputs:**
- Context snapshot with decision (“ship redesign or iterate”) and constraints
- Test plan with hypotheses around CTA clarity, trust, and error recovery
- 5–8 neutral tasks with starting states (coupon, guest vs logged-in, payment method)
- Moderator guide with probes (“what were you expecting?”)
- Notes template + issue log with severity/frequency and a prioritized top-10 list
- Synthesis readout with quick-win microcopy fixes vs structural fixes

## Example 2 — Wizard of Oz validation (early-stage)

**Prompt:** “Design a Wizard of Oz usability test to validate an AI ‘auto-triage’ feature before building it. We can manually do the triage behind the scenes. 5 sessions.”

**Expected outputs:**
- Stimulus plan that defines what is simulated vs real and who performs backstage work
- Tasks focused on value/outcome (“resolve issue faster”) rather than UI polish
- Evidence plan to capture trust/understanding moments and failure modes
- Issue log format that captures confidence/expectations, not just clicks
- Next steps that include a follow-up prototype iteration or small experiment

## Boundary example — Asking for proof of impact

**Prompt:** “Run a usability test to prove our redesign increases retention by 10%.”

**Expected response:**
- Explain that small-n usability tests diagnose friction and comprehension but don’t estimate causal lift
- Propose pairing usability with instrumentation and an experiment or cohort analysis
- Still offer a usability plan focused on identifying retention blockers (activation, habit loop tasks)

