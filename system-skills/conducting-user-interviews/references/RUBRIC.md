# Rubric (Conducting User Interviews)

Score each dimension **1–5** (1 = poor, 3 = acceptable, 5 = excellent). Include notes and a short improvement plan for any score ≤ 3.

## 1) Decision clarity
- **1:** No decision; interviews are “general learning”.
- **3:** Decision exists but is broad; success criteria are vague.
- **5:** Clear decision + deadline + success definition; unknowns are explicit.

## 2) Participant fit
- **1:** Participants are convenient but mismatched; no recency.
- **3:** Mostly fits; some interviews are low-signal.
- **5:** Strong fit with behavior/situation criteria; deliberate edge cases; recency prioritized when relevant.

## 3) Guide quality (story-first)
- **1:** Mostly opinions/hypotheticals; leading questions.
- **3:** Mix of story + opinion; probes are inconsistent.
- **5:** Strong story elicitation, neutral wording, clear probes and time boxes.

## 4) Execution and evidence capture
- **1:** Sparse notes; few quotes; no debrief.
- **3:** Adequate notes; some quotes; inconsistent debriefing.
- **5:** Clean notes + quotes; consistent debrief; clear separation of observation vs interpretation.

## 5) Synthesis quality
- **1:** List of anecdotes; no structure; no contradictions.
- **3:** Themes exist; evidence is partial; confidence unclear.
- **5:** Themes tied to outcomes; evidence strength and segmentation are explicit; insights translate into opportunities.

## 6) Actionability
- **1:** No recommendations or next steps.
- **3:** Recommendations exist but are generic.
- **5:** Recommendations are specific, scoped, and paired with validation steps and owners (where possible).

## 7) Ethics and safety
- **1:** No consent/recording clarity; privacy risks ignored.
- **3:** Basic consent included; storage/retention unclear.
- **5:** Consent and minimization are explicit; risks and mitigations are documented.

## Suggested overall rating
- **Excellent:** avg ≥ 4.2, no dimension < 4
- **Good:** avg 3.5–4.1, no dimension < 3
- **Needs work:** avg < 3.5 or any dimension < 3

