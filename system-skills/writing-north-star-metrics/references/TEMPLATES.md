# Templates (Copy/Paste)

Use these templates to produce the **North Star Metric Pack**.

## 0) Context snapshot (bullets)
- Product:
- Primary customer segment:
- Value moment:
- Business model:
- Strategic goal (next 6–12 months):
- Horizon (quarter/year):
- Current metric pain/misalignment:
- Measurement constraints (sources/latency/gaps):
- Stakeholders to align:

## 1) North Star Narrative
### North Star statement
One sentence: “We exist to ___ for ___ by ___.”

### Customer value model (short)
- The customer succeeds when:
- The “value moment” is:
- What’s in scope:
- What’s out of scope:
- Key tradeoffs we’ll manage with guardrails:

### How to use this North Star
- Decisions it should settle:
- Decisions it should NOT settle:
- Primary teams/levers that can influence it:

## 2) Candidate metrics + evaluation table
List 3–5 candidates, then fill this table:

| Candidate metric | Measures customer value? | Definition (1–2 lines) | Update frequency | Controllable this quarter? | Gaming risk | Instrumentation readiness | Notes |
|---|---|---|---|---|---|---|---|
| | | | | | | | |

## 3) Chosen North Star Metric spec
### Metric
- Name:
- One-line definition:
- Why this metric represents customer value:

### Formula
- Numerator:
- Denominator (if applicable):
- Time window:
- Unit:

### Rules
- Inclusion/exclusion rules:
- “Active” definition (if applicable):
- Quality threshold (if applicable):

### Operations
- Segmentation slices:
- Data source(s):
- Data latency/freshness:
- Owner (person/team):
- Review cadence:

### Example calculation
- Example inputs:
- Computed result:

## 4) Driver tree (inputs/proxies) + levers
Create 3–7 drivers and 1–3 leading inputs per driver:

| Driver | Why it matters | Leading input/proxy metrics | Example levers (initiatives/experiments) | Notes |
|---|---|---|---|---|
| | | | | |

### Guardrails (anti-gaming / harm prevention)
List 2–6 guardrails you will monitor:
- Guardrail metric:
  - Why it matters:
  - Threshold / trigger (if known):

## 5) Validation & rollout plan
### Validation
- Sanity checks:
- Leadingness/correlation checks:
- Known caveats:

### Rollout
- Dashboard location:
- Weekly review owner + attendees:
- Monthly spec review owner:
- Communication plan (who gets what update):
- Decision rules (“if X happens, we do Y”):

## 6) Risks / Open questions / Next steps (required)
### Risks
- …

### Open questions
- …

### Next steps
1) …
2) …

