# Checklists

Use these to validate the North Star Metric Pack before finalizing.

## A) North Star Narrative checklist
- [ ] Clearly states **who** the customer is and what job they’re hiring the product for
- [ ] Defines the **value moment** in plain language
- [ ] Explains why the North Star is the **decision tie-breaker**
- [ ] Lists what’s **in scope** and **out of scope**
- [ ] Notes key tradeoffs and what guardrails will manage them

## B) Candidate metrics checklist
- [ ] 3–5 candidates are presented (not just one)
- [ ] Each candidate measures **delivered customer value**, not internal activity
- [ ] Definitions are specific enough to compute
- [ ] At least one candidate considers **friction reduction** / “absence of pain” when relevant
- [ ] Each candidate includes an explicit gaming risk / ecosystem impact note

## C) Chosen metric checklist
- [ ] The chosen metric is a strong tie-breaker for product decisions
- [ ] It can be influenced within the stated horizon (or has explicit input metrics that can)
- [ ] It is not purely a lagging outcome used as the only operating goal (e.g., “retention” alone)
- [ ] It is simple enough to remember and explain
- [ ] It has 1–2 explicit guardrails (quality/trust/margin/customer harm)

## D) Metric spec checklist (unambiguous computation)
- [ ] Numerator/denominator/time window/unit are defined
- [ ] Inclusion/exclusion rules are clear
- [ ] “Active” and cohort definitions are clear (if applicable)
- [ ] Segments/slices are listed
- [ ] Data sources + latency are documented
- [ ] Owner and review cadence are defined
- [ ] Example calculation is provided

## E) Driver tree checklist
- [ ] 3–7 drivers decompose the North Star
- [ ] Each driver has 1–3 **leading input/proxy metrics**
- [ ] Each input metric has at least one realistic lever (initiative/experiment)
- [ ] Guardrails are listed and aligned to known risks

## F) Validation & rollout checklist
- [ ] Includes sanity checks (what should move it, what shouldn’t)
- [ ] Includes a plan to validate leading inputs vs outcomes
- [ ] Defines dashboards/cadence/owners
- [ ] Includes decision rules and communication plan

## G) Final pack checklist (must-have sections)
- [ ] Context snapshot
- [ ] North Star Narrative
- [ ] Candidate metrics + evaluation table
- [ ] Chosen metric spec
- [ ] Driver tree + guardrails
- [ ] Validation & rollout plan
- [ ] Risks
- [ ] Open questions
- [ ] Next steps

## H) Common anti-patterns (use as a final scan)
- [ ] Metric is a vanity number (easy to increase without delivering value)
- [ ] Metric is internal activity (tickets closed, features shipped) rather than customer outcome
- [ ] Metric is too lagging to steer (and no controllable inputs are defined)
- [ ] Metric is a black-box composite that hides drivers and levers
- [ ] Metric invites gaming or customer harm (and guardrails are missing)
- [ ] “North Star” is really multiple metrics with no primary tie-breaker

