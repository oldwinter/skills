# Workflow (Expanded)

This file expands the steps from `../SKILL.md` with extra guidance and decision heuristics.

## Step 1 — Intake + decision framing
Anchor on a decision, not curiosity.

Output a **Context snapshot**:
- Product + ICP + use case
- Decision to support + deadline
- Where the question came from (sales losses, market shift, leadership request)
- Constraints (geo, compliance, price band, ecosystem)
- Time box and desired confidence level

Heuristic: if you can’t name the decision, you’ll produce a “logo garden”.

## Step 2 — Competitive alternatives mapping (the real competition)
Start with: “What would the customer do if we didn’t exist?”

Include categories:
- **Status quo:** spreadsheets, email, existing vendor contracts
- **Workarounds:** manual processes, scripts, internal tools
- **Analog / traditional:** offline solutions, consultants, “Yellow Pages”-style analogs
- **Direct competitors:** same category positioning
- **Indirect competitors:** adjacent categories solving the same job differently
- **Non-consumption:** “do nothing” due to cost/complexity/risk

Output a simple map (even as a table) and identify the likely “deal alternative”.

## Step 3 — Evidence gathering (time-boxed and explicit)
Prefer **public + attributable** sources.

For each competitor/alternative capture:
- Positioning claim (1–2 sentences)
- Target segment + use case
- 3–5 notable capabilities (only those tied to decision criteria)
- Pricing model and packaging signals (as available)
- Distribution/GTM signals (self-serve vs enterprise, partners, marketplaces)
- Evidence links + confidence

Avoid: confidential scraping, speculative “insider” claims, or pretending certainty without sources.

## Step 4 — Customer decision criteria + comparison matrix
Build criteria from the customer POV:
- Desired outcomes (speed, quality, risk reduction, compliance, revenue)
- Switching costs and lock-in
- Trust/brand and perceived safety
- Time-to-value and implementation complexity
- Ecosystem fit (integrations, workflow compatibility)
- Total cost (license + ops + people time)

Output:
- A criteria list (6–10 items)
- A matrix scoring/notes per alternative
- “Why they win” bullets per competitor

## Step 5 — Differentiation & positioning hypotheses
Write 2–3 hypotheses as explicit “against X” statements.

Each hypothesis includes:
- Target ICP + use case
- “Best for” statement
- Primary differentiation vs the true alternative (not just the closest logo)
- Proof points (features, data, references, guarantees, ecosystem)
- Tradeoffs/non-goals (what you don’t do)

Heuristic: if the hypothesis could apply vs any competitor, it’s not specific enough.

## Step 6 — Win themes + battlecards (make it usable)
Battlecards are for *live decisions*, not product encyclopedias.

Each battlecard should include:
- When we win / when we lose (deal signals)
- 3–5 win themes (what to lead with)
- Landmines (what not to say) + traps to avoid
- Objection handling (short talk tracks)
- Proof points + references to evidence

## Step 7 — Recommendations (turn insight into action)
Tie every recommendation to:
- A decision criterion
- A win theme or loss risk
- A clear owner/time horizon (if known)

Include at least one “stop doing” recommendation if applicable.

## Step 8 — Monitoring plan + quality gate
Competitive analysis decays quickly.

Monitoring plan should define:
- Signals to watch (product changes, pricing, messaging, hiring, reviews, traffic/SEO, partnerships)
- Cadence (weekly/monthly/quarterly)
- Owners and update triggers (e.g., win/loss pattern changes; major competitor launch)

Before finalizing:
- Run [CHECKLISTS.md](CHECKLISTS.md)
- Score with [RUBRIC.md](RUBRIC.md)
- Add **Risks / Open questions / Next steps**

