# Intake (Usability Testing)

Ask **up to 5 questions at a time**. If answers aren’t available, proceed with explicit assumptions and label unknowns.

## Minimum intake (pick the best 5)
1) **What decision will this usability test inform?** By when? (e.g., “ship onboarding redesign”, “choose between 2 IA options”, “fix top conversion blockers”)
2) **Who are we testing with?** Role, context, and what makes someone a good fit (and who is explicitly out of scope).
3) **What exactly are we testing?** Flow(s), feature(s), and starting state(s). Provide prototype/build link if available.
4) **Where is the product used?** Platform (web/mobile), device constraints, accessibility requirements, remote vs in-person.
5) **What’s the preferred session format?** Moderated vs unmoderated; recorded vs not; observers allowed vs not.

## Logistics + constraints (as needed)
- How many sessions can we run, and in what window? Any “no reschedule” dates?
- Incentives and recruiting channels available? (in-product, email list, sales pipeline, support tickets, community)
- Any privacy/compliance constraints? (PII exposure, NDA needs, data retention policy)
- What evidence already exists? (analytics funnel, support tickets, prior research, heatmaps)
- What are the top 3 suspected friction points/hypotheses (if any)?

## If the user can’t answer
Proceed with:
- A clear decision hypothesis + success definition
- A default plan for **5 moderated sessions** (remote) with a defined target segment
- 5–8 neutral tasks + a moderator guide and notes/issue-log templates
- A synthesis format that outputs a prioritized fix list with evidence and expected impact

