# Examples (expanded)

These are short, structured examples of what “good” looks like. Adapt to your context.

## Example 1 — Internal platform (paved roads)

**Scenario:** Internal ML platform used by 40 engineers. Biggest pain is shipping models reliably and quickly. PII present; SOC2. Two platform engineers.

**What a strong output includes:**
- A Platform Product Charter that names users (ML engineers vs app engineers vs analysts) and defines outcomes (deployment cycle time, incident rate).
- A surface map with paved-road defaults (auth, logging, model registry, deployment pipeline, safe data access).
- Governance that treats AI context/data as first-class (permissions, audit logs, eval/monitoring).
- A realistic Now/Next/Later roadmap that starts with a narrow paved road and expands after adoption signals.

## Example 2 — External ecosystem (API + partners)

**Scenario:** Analytics product wants 20 high-quality integrations in 12 months; reliability cannot regress.

**What a strong output includes:**
- A stage diagnosis that acknowledges support/versioning commitments before going fully public.
- Incentives and a seeding plan (reference integrations, co-marketing, marketplace listing, “fast-path” reviews).
- Governance: auth model, quotas, deprecation policy, partner tiers, parity rules.
- A roadmap that sequences “platform readiness” (docs, SDKs, testing harness) before broad opening.

## Boundary example — “Become a platform”

**Scenario:** Stakeholder wants “platform strategy like Apple” with no concrete users/jobs or loop.

**Expected response:**
- Ask intake questions (users/jobs, what becomes easier, current pains).
- Propose a smaller internal platform-as-product charter first; defer external opening until a compounding loop is credible and support/governance is ready.

